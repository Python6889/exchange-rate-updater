#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ²ªæ¸¯é€šæ±‡ç‡è‡ªåŠ¨æ›´æ–°ç¨‹åº - GitHub Actionsç‰ˆæœ¬
"""

import os
import sys
import akshare as ak
import pandas as pd
import requests
from datetime import datetime

# ==================== é…ç½®éƒ¨åˆ† ====================
# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®ï¼ˆGitHub Actions Secretsï¼‰
APP_ID = os.environ.get('APP_ID')
APP_SECRET = os.environ.get('APP_SECRET')
TABLE_TOKEN = os.environ.get('TABLE_TOKEN')
SHEET_ID = os.environ.get('SHEET_ID')

# ==================== æ ¸å¿ƒå‡½æ•° ====================

def get_feishu_token():
    """è·å–é£ä¹¦APIçš„è®¿é—®ä»¤ç‰Œ"""
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    headers = {"Content-Type": "application/json"}
    data = {"app_id": APP_ID, "app_secret": APP_SECRET}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        result = response.json()
        
        if result.get("code") == 0:
            print("âœ… æˆåŠŸè·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
            return result["tenant_access_token"]
        else:
            print(f"âŒ è·å–ä»¤ç‰Œå¤±è´¥: {result}")
            return None
    except Exception as e:
        print(f"âŒ è·å–ä»¤ç‰Œæ—¶å‡ºé”™: {e}")
        return None

def get_settlement_exchange_rate():
    """ä½¿ç”¨akshareè·å–æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ•°æ®"""
    try:
        print("æ­£åœ¨ä»akshareè·å–æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ•°æ®...")
        df = ak.stock_sgt_settlement_exchange_rate_sse()
        
        if df is not None and not df.empty:
            print(f"âœ… æˆåŠŸè·å–ç»“ç®—æ±‡ç‡æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
            return df
        else:
            print("âš ï¸ ç»“ç®—æ±‡ç‡æ•°æ®ä¸ºç©º")
            return pd.DataFrame()
    except Exception as e:
        print(f"âŒ è·å–ç»“ç®—æ±‡ç‡æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def get_reference_exchange_rate():
    """ä½¿ç”¨akshareè·å–æ²ªæ¸¯é€šå‚è€ƒæ±‡ç‡æ•°æ®"""
    try:
        print("æ­£åœ¨ä»akshareè·å–æ²ªæ¸¯é€šå‚è€ƒæ±‡ç‡æ•°æ®...")
        df = ak.stock_sgt_reference_exchange_rate_sse()
        
        if df is not None and not df.empty:
            print(f"âœ… æˆåŠŸè·å–å‚è€ƒæ±‡ç‡æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
            return df
        else:
            print("âš ï¸ å‚è€ƒæ±‡ç‡æ•°æ®ä¸ºç©º")
            return pd.DataFrame()
    except Exception as e:
        print(f"âŒ è·å–å‚è€ƒæ±‡ç‡æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def merge_and_select_exchange_data(settlement_df, reference_df):
    """
    åˆå¹¶ç»“ç®—æ±‡ç‡å’Œå‚è€ƒæ±‡ç‡æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨ç»“ç®—æ±‡ç‡
    """
    print("ğŸ”„ åˆå¹¶ç»“ç®—æ±‡ç‡å’Œå‚è€ƒæ±‡ç‡æ•°æ®...")
    
    # å¦‚æœä¸¤ä¸ªæ•°æ®éƒ½ä¸ºç©º
    if settlement_df.empty and reference_df.empty:
        print("âš ï¸ ç»“ç®—æ±‡ç‡å’Œå‚è€ƒæ±‡ç‡æ•°æ®éƒ½ä¸ºç©º")
        return pd.DataFrame()
    
    # å¦‚æœåªæœ‰ç»“ç®—æ±‡ç‡æ•°æ®
    if not settlement_df.empty and reference_df.empty:
        print("ğŸ“Š åªä½¿ç”¨ç»“ç®—æ±‡ç‡æ•°æ®")
        settlement_df['æ±‡ç‡ç±»å‹'] = 'ç»“ç®—æ±‡ç‡'
        return settlement_df
    
    # å¦‚æœåªæœ‰å‚è€ƒæ±‡ç‡æ•°æ®
    if settlement_df.empty and not reference_df.empty:
        print("ğŸ“Š åªä½¿ç”¨å‚è€ƒæ±‡ç‡æ•°æ®")
        reference_df['æ±‡ç‡ç±»å‹'] = 'å‚è€ƒæ±‡ç‡'
        return reference_df
    
    # å¦‚æœä¸¤ä¸ªæ•°æ®éƒ½æœ‰ï¼Œè¿›è¡Œåˆå¹¶
    print("ğŸ“Š åˆå¹¶ä¸¤ç§æ±‡ç‡æ•°æ®...")
    
    # æ ‡å‡†åŒ–æ—¥æœŸåˆ— - å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ—¥æœŸ
    settlement_df = settlement_df.copy()
    reference_df = reference_df.copy()
    
    # é‡å‘½åç¬¬ä¸€åˆ—ä¸º'äº¤æ˜“æ—¥æœŸ'
    settlement_df.rename(columns={settlement_df.columns[0]: 'äº¤æ˜“æ—¥æœŸ'}, inplace=True)
    reference_df.rename(columns={reference_df.columns[0]: 'äº¤æ˜“æ—¥æœŸ'}, inplace=True)
    
    # ç¡®ä¿äº¤æ˜“æ—¥æœŸæ˜¯å­—ç¬¦ä¸²ç±»å‹
    settlement_df['äº¤æ˜“æ—¥æœŸ'] = settlement_df['äº¤æ˜“æ—¥æœŸ'].astype(str)
    reference_df['äº¤æ˜“æ—¥æœŸ'] = reference_df['äº¤æ˜“æ—¥æœŸ'].astype(str)
    
    # æ·»åŠ æ±‡ç‡ç±»å‹åˆ—
    settlement_df['æ±‡ç‡ç±»å‹'] = 'ç»“ç®—æ±‡ç‡'
    reference_df['æ±‡ç‡ç±»å‹'] = 'å‚è€ƒæ±‡ç‡'
    
    # è·å–ç»“ç®—æ±‡ç‡çš„æ‰€æœ‰æ—¥æœŸ
    settlement_dates = set(settlement_df['äº¤æ˜“æ—¥æœŸ'].unique())
    print(f"ç»“ç®—æ±‡ç‡æœ‰ {len(settlement_dates)} ä¸ªä¸åŒæ—¥æœŸ")
    
    # è·å–å‚è€ƒæ±‡ç‡çš„æ‰€æœ‰æ—¥æœŸ
    reference_dates = set(reference_df['äº¤æ˜“æ—¥æœŸ'].unique())
    print(f"å‚è€ƒæ±‡ç‡æœ‰ {len(reference_dates)} ä¸ªä¸åŒæ—¥æœŸ")
    
    # æ‰¾å‡ºåªåœ¨å‚è€ƒæ±‡ç‡ä¸­å­˜åœ¨çš„æ—¥æœŸ
    reference_only_dates = reference_dates - settlement_dates
    print(f"åªåœ¨å‚è€ƒæ±‡ç‡ä¸­å­˜åœ¨çš„æ—¥æœŸ: {len(reference_only_dates)} ä¸ª")
    
    # ä»å‚è€ƒæ±‡ç‡ä¸­ç­›é€‰å‡ºç»“ç®—æ±‡ç‡æ²¡æœ‰çš„æ—¥æœŸ
    reference_only_df = reference_df[reference_df['äº¤æ˜“æ—¥æœŸ'].isin(reference_only_dates)].copy()
    
    # åˆå¹¶æ•°æ®ï¼šç»“ç®—æ±‡ç‡ + å‚è€ƒæ±‡ç‡ä¸­ç»“ç®—æ±‡ç‡æ²¡æœ‰çš„æ—¥æœŸ
    merged_df = pd.concat([settlement_df, reference_only_df], ignore_index=True)
    
    # æŒ‰äº¤æ˜“æ—¥æœŸæ’åº
    merged_df.sort_values('äº¤æ˜“æ—¥æœŸ', ascending=False, inplace=True)
    merged_df.reset_index(drop=True, inplace=True)
    
    print(f"âœ… åˆå¹¶åæ•°æ®: {len(merged_df)} æ¡è®°å½•")
    print(f"å…¶ä¸­ç»“ç®—æ±‡ç‡: {len(settlement_df)} æ¡")
    print(f"å…¶ä¸­å‚è€ƒæ±‡ç‡: {len(reference_only_df)} æ¡")
    
    return merged_df

def read_existing_feishu_data(token):
    """ä»é£ä¹¦è¡¨æ ¼è¯»å–ç°æœ‰æ•°æ®"""
    try:
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values/{SHEET_ID}"
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        print("æ­£åœ¨ä»é£ä¹¦è¡¨æ ¼è¯»å–ç°æœ‰æ•°æ®...")
        response = requests.get(url, headers=headers)
        result = response.json()
        
        if result.get("code") == 0:
            data = result.get("data", {})
            values = data.get("valueRange", {}).get("values", [])
            
            if not values or len(values) <= 1:
                print("ğŸ“­ è¡¨æ ¼ä¸­æ²¡æœ‰æ•°æ®æˆ–åªæœ‰è¡¨å¤´")
                return []
            
            # ä»ç¬¬äºŒè¡Œå¼€å§‹æ˜¯æ•°æ®ï¼ˆç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼‰
            existing_data = values[1:]
            print(f"ğŸ“Š è¯»å–åˆ° {len(existing_data)} æ¡ç°æœ‰æ•°æ®")
            return existing_data
        else:
            print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {result}")
            return []
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®æ—¶å‡ºé”™: {e}")
        return []

def identify_new_data(df, existing_data):
    """è¯†åˆ«æ–°å¢æ•°æ®"""
    if df.empty:
        print("âš ï¸ æ²¡æœ‰æ–°æ•°æ®å¯å¤„ç†")
        return pd.DataFrame()
    
    if not existing_data:
        print("ğŸ“ è¡¨æ ¼ä¸ºç©ºï¼Œæ‰€æœ‰æ•°æ®éƒ½æ˜¯æ–°å¢æ•°æ®")
        return df
    
    try:
        # è·å–ç°æœ‰æ•°æ®ä¸­çš„æ—¥æœŸï¼ˆå‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ—¥æœŸï¼‰
        existing_dates = []
        for row in existing_data:
            if row:
                existing_dates.append(str(row[0]))
        
        print(f"ğŸ“… ç°æœ‰æ•°æ®ä¸­çš„æ—¥æœŸæ•°é‡: {len(existing_dates)}")
        
        # è·å–æ–°æ•°æ®ä¸­çš„æ—¥æœŸ
        new_dates = df['äº¤æ˜“æ—¥æœŸ'].astype(str).tolist()
        
        # æ‰¾å‡ºæ–°å¢çš„æ—¥æœŸ
        new_date_indices = []
        for i, date in enumerate(new_dates):
            if str(date) not in existing_dates:
                new_date_indices.append(i)
        
        print(f"ğŸ” æ‰¾åˆ° {len(new_date_indices)} æ¡æ–°å¢æ•°æ®")
        
        if new_date_indices:
            # æå–æ–°å¢æ•°æ®
            new_data_df = df.iloc[new_date_indices].copy()
            
            # æ˜¾ç¤ºæ–°å¢æ•°æ®çš„æ—¥æœŸå’Œç±»å‹
            if 'äº¤æ˜“æ—¥æœŸ' in new_data_df.columns and 'æ±‡ç‡ç±»å‹' in new_data_df.columns:
                print("æ–°å¢æ•°æ®è¯¦æƒ…:")
                for idx, row in new_data_df.iterrows():
                    print(f"  æ—¥æœŸ: {row['äº¤æ˜“æ—¥æœŸ']}, ç±»å‹: {row['æ±‡ç‡ç±»å‹']}")
            
            return new_data_df
        else:
            print("âœ… æ²¡æœ‰å‘ç°æ–°å¢æ•°æ®ï¼Œæ‰€æœ‰æ•°æ®éƒ½å·²å­˜åœ¨")
            return pd.DataFrame()
            
    except Exception as e:
        print(f"âŒ è¯†åˆ«æ–°å¢æ•°æ®æ—¶å‡ºé”™: {e}")
        return pd.DataFrame()

def prepare_update_data(new_data_df):
    """å‡†å¤‡è¦æ›´æ–°åˆ°é£ä¹¦çš„æ•°æ®æ ¼å¼"""
    if new_data_df.empty:
        print("âš ï¸ æ²¡æœ‰æ–°å¢æ•°æ®éœ€è¦æ›´æ–°")
        return []
    
    try:
        # æ·»åŠ æ›´æ–°æ—¶é—´åˆ—
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        new_data_df = new_data_df.copy()
        new_data_df['æ›´æ–°æ—¶é—´'] = current_time
        
        # å°†æ•°æ®è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        data_rows = []
        for _, row in new_data_df.iterrows():
            row_data = []
            for value in row:
                if pd.isna(value):
                    row_data.append("")
                else:
                    row_data.append(str(value))
            data_rows.append(row_data)
        
        print(f"âœ… å‡†å¤‡å®Œæˆ {len(data_rows)} è¡Œæ–°å¢æ•°æ®")
        return data_rows
    except Exception as e:
        print(f"âŒ å‡†å¤‡æ•°æ®æ—¶å‡ºé”™: {e}")
        return []

def append_to_feishu(feishu_data, token):
    """å°†æ–°å¢æ•°æ®è¿½åŠ åˆ°é£ä¹¦è¡¨æ ¼"""
    if not feishu_data:
        print("âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦è¿½åŠ ")
        return True
    
    try:
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values_append"
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json; charset=utf-8"
        }
        
        request_data = {
            "valueRange": {
                "range": SHEET_ID,
                "values": feishu_data
            }
        }
        
        print(f"æ­£åœ¨è¿½åŠ  {len(feishu_data)} è¡Œæ–°æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼...")
        response = requests.post(url, headers=headers, json=request_data)
        result = response.json()
        
        if result.get("code") == 0:
            updates = result.get("data", {}).get("updates", {})
            print(f"âœ… æˆåŠŸè¿½åŠ æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼ï¼")
            print(f"æ›´æ–°èŒƒå›´ï¼š{updates.get('updatedRange', 'æœªçŸ¥')}")
            print(f"æ›´æ–°è¡Œæ•°ï¼š{updates.get('updatedRows', 'æœªçŸ¥')}")
            return True
        else:
            print(f"âŒ è¿½åŠ æ•°æ®å¤±è´¥: {result}")
            return False
    except Exception as e:
        print(f"âŒ è¿½åŠ æ•°æ®æ—¶å‡ºé”™: {e}")
        return False

def incremental_update():
    """ä¸»å‡½æ•°ï¼šå®ç°å¢é‡æ›´æ–°"""
    print("=" * 60)
    print("æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ•°æ® - å¢é‡æ›´æ–°")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if not all([APP_ID, APP_SECRET, TABLE_TOKEN, SHEET_ID]):
            print("âŒ ç¯å¢ƒå˜é‡æœªè®¾ç½®å®Œæ•´")
            print("è¯·åœ¨GitHubä»“åº“çš„Settings -> Secrets and variables -> Actionsä¸­è®¾ç½®:")
            print("APP_ID, APP_SECRET, TABLE_TOKEN, SHEET_ID")
            return False
        
        # æ­¥éª¤1ï¼šè·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ
        print("\n1ï¸âƒ£ è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
        token = get_feishu_token()
        if not token:
            print("âŒ æ— æ³•è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
            return False
        
        # æ­¥éª¤2ï¼šä»é£ä¹¦è¡¨æ ¼è¯»å–ç°æœ‰æ•°æ®
        print("\n2ï¸âƒ£ è¯»å–é£ä¹¦è¡¨æ ¼ä¸­çš„ç°æœ‰æ•°æ®")
        existing_data = read_existing_feishu_data(token)
        
        # æ­¥éª¤3ï¼šè·å–æœ€æ–°çš„ç»“ç®—æ±‡ç‡å’Œå‚è€ƒæ±‡ç‡æ•°æ®
        print("\n3ï¸âƒ£ è·å–æœ€æ–°çš„æ±‡ç‡æ•°æ®")
        settlement_df = get_settlement_exchange_rate()
        reference_df = get_reference_exchange_rate()
        
        # æ­¥éª¤4ï¼šåˆå¹¶æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨ç»“ç®—æ±‡ç‡
        print("\n4ï¸âƒ£ åˆå¹¶æ±‡ç‡æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ç»“ç®—æ±‡ç‡ï¼‰")
        df = merge_and_select_exchange_data(settlement_df, reference_df)
        
        if df.empty:
            print("âŒ æ— æ³•è·å–æœ‰æ•ˆæ•°æ®")
            return False
        
        # æ­¥éª¤5ï¼šè¯†åˆ«æ–°å¢æ•°æ®
        print("\n5ï¸âƒ£ è¯†åˆ«æ–°å¢æ•°æ®")
        new_data_df = identify_new_data(df, existing_data)
        
        if new_data_df.empty:
            print("âœ… æ²¡æœ‰å‘ç°æ–°å¢æ•°æ®ï¼Œæ— éœ€æ›´æ–°")
            return True
        
        # æ­¥éª¤6ï¼šå‡†å¤‡æ•°æ®æ ¼å¼
        print("\n6ï¸âƒ£ å‡†å¤‡æ•°æ®æ ¼å¼")
        feishu_data = prepare_update_data(new_data_df)
        
        if not feishu_data:
            print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥")
            return False
        
        # æ­¥éª¤7ï¼šè¿½åŠ æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼
        print("\n7ï¸âƒ£ è¿½åŠ æ–°å¢æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼")
        success = append_to_feishu(feishu_data, token)
        
        if success:
            print("\n" + "=" * 60)
            print(f"ğŸ‰ å¢é‡æ›´æ–°æˆåŠŸï¼æ–°å¢ {len(feishu_data)} æ¡æ•°æ®")
            print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("=" * 60)
            return True
        else:
            print("\nâŒ å¢é‡æ›´æ–°å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    print("å¼€å§‹æ‰§è¡Œæ²ªæ¸¯é€šæ±‡ç‡æ›´æ–°ç¨‹åº...")
    result = incremental_update()
    
    if result:
        print("ç¨‹åºæ‰§è¡ŒæˆåŠŸï¼")
        sys.exit(0)  # æˆåŠŸé€€å‡º
    else:
        print("ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼")
        sys.exit(1)  # å¤±è´¥é€€å‡º