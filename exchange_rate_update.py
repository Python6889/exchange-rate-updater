#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡è‡ªåŠ¨æ›´æ–°ç¨‹åº - GitHub Actionsç‰ˆæœ¬
ä»…ä½¿ç”¨ç»“ç®—æ±‡ç‡æ•°æ®ï¼Œå®ç°å¢é‡æ›´æ–°
"""

import os
import sys
import akshare as ak
import pandas as pd
import requests
from datetime import datetime

# ==================== é…ç½®éƒ¨åˆ† ====================
# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®ï¼ˆGitHub Actions Secretsï¼‰
APP_ID = os.environ.get('APP_ID')
APP_SECRET = os.environ.get('APP_SECRET')
TABLE_TOKEN = os.environ.get('TABLE_TOKEN')
SHEET_ID = os.environ.get('SHEET_ID')

# ==================== æ ¸å¿ƒå‡½æ•° ====================

def get_feishu_token():
    """è·å–é£ä¹¦APIçš„è®¿é—®ä»¤ç‰Œ"""
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    headers = {"Content-Type": "application/json"}
    data = {"app_id": APP_ID, "app_secret": APP_SECRET}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        result = response.json()
        
        if result.get("code") == 0:
            print("âœ… æˆåŠŸè·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
            return result["tenant_access_token"]
        else:
            print(f"âŒ è·å–ä»¤ç‰Œå¤±è´¥: {result}")
            return None
    except Exception as e:
        print(f"âŒ è·å–ä»¤ç‰Œæ—¶å‡ºé”™: {e}")
        return None

def get_settlement_exchange_rate():
    """ä½¿ç”¨akshareè·å–æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ•°æ®"""
    try:
        print("æ­£åœ¨ä»akshareè·å–æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ•°æ®...")
        df = ak.stock_sgt_settlement_exchange_rate_sse()
        
        if df is not None and not df.empty:
            print(f"âœ… æˆåŠŸè·å–ç»“ç®—æ±‡ç‡æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
            
            # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
            print(f"æ•°æ®åˆ—åï¼š{df.columns.tolist()}")
            print(f"æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{df.iloc[0, 0]} åˆ° {df.iloc[-1, 0]}")
            
            return df
        else:
            print("âš ï¸ ç»“ç®—æ±‡ç‡æ•°æ®ä¸ºç©º")
            return pd.DataFrame()
    except Exception as e:
        print(f"âŒ è·å–ç»“ç®—æ±‡ç‡æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def read_existing_feishu_data(token):
    """ä»é£ä¹¦è¡¨æ ¼è¯»å–ç°æœ‰æ•°æ®"""
    try:
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values/{SHEET_ID}"
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        print("æ­£åœ¨ä»é£ä¹¦è¡¨æ ¼è¯»å–ç°æœ‰æ•°æ®...")
        response = requests.get(url, headers=headers)
        result = response.json()
        
        if result.get("code") == 0:
            data = result.get("data", {})
            values = data.get("valueRange", {}).get("values", [])
            
            if not values or len(values) <= 1:
                print("ğŸ“­ è¡¨æ ¼ä¸­æ²¡æœ‰æ•°æ®æˆ–åªæœ‰è¡¨å¤´")
                return [], []  # è¿”å›ç©ºçš„æ•°æ®å’Œè¡¨å¤´
            
            # ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´
            headers = values[0]
            # ä»ç¬¬äºŒè¡Œå¼€å§‹æ˜¯æ•°æ®
            existing_data = values[1:]
            
            print(f"ğŸ“Š è¯»å–åˆ° {len(existing_data)} æ¡ç°æœ‰æ•°æ®")
            print(f"è¡¨å¤´ï¼š{headers}")
            
            return existing_data, headers
        else:
            print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {result}")
            return [], []
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®æ—¶å‡ºé”™: {e}")
        return [], []

def prepare_new_data(df):
    """å‡†å¤‡æ–°çš„ç»“ç®—æ±‡ç‡æ•°æ®"""
    if df is None or df.empty:
        print("âš ï¸ æ²¡æœ‰æ–°æ•°æ®å¯å¤„ç†")
        return pd.DataFrame()
    
    try:
        # æ·»åŠ æ›´æ–°æ—¶é—´åˆ—
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        df = df.copy()
        
        # å¦‚æœè¿˜æ²¡æœ‰æ›´æ–°æ—¶é—´åˆ—ï¼Œåˆ™æ·»åŠ 
        if 'æ›´æ–°æ—¶é—´' not in df.columns:
            df['æ›´æ–°æ—¶é—´'] = current_time
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
        # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ—¥æœŸåˆ—
        date_column = df.columns[0]
        df = df.sort_values(by=date_column, ascending=False).reset_index(drop=True)
        
        print(f"âœ… å‡†å¤‡å®Œæˆ {len(df)} æ¡ç»“ç®—æ±‡ç‡æ•°æ®")
        return df
    except Exception as e:
        print(f"âŒ å‡†å¤‡æ•°æ®æ—¶å‡ºé”™: {e}")
        return pd.DataFrame()

def identify_new_data(df, existing_data, existing_headers):
    """
    æ¯”è¾ƒæ–°è·å–çš„æ•°æ®å’Œç°æœ‰æ•°æ®ï¼Œæ‰¾å‡ºæ–°å¢çš„æ•°æ®
    
    å‚æ•°:
    df: æ–°è·å–çš„DataFrameæ•°æ®
    existing_data: é£ä¹¦è¡¨æ ¼ä¸­ç°æœ‰çš„æ•°æ®ï¼ˆäºŒç»´åˆ—è¡¨ï¼‰
    existing_headers: é£ä¹¦è¡¨æ ¼ä¸­çš„è¡¨å¤´
    
    è¿”å›:
    new_data_df: æ–°å¢æ•°æ®çš„DataFrame
    """
    if df is None or df.empty:
        print("âš ï¸ æ²¡æœ‰æ–°æ•°æ®å¯å¤„ç†")
        return pd.DataFrame()
    
    if not existing_data:  # å¦‚æœè¡¨æ ¼ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ‰€æœ‰æ•°æ®éƒ½æ˜¯æ–°çš„
        print("ğŸ“ è¡¨æ ¼ä¸ºç©ºï¼Œæ‰€æœ‰æ•°æ®éƒ½æ˜¯æ–°å¢æ•°æ®")
        return df
    
    try:
        # å°†ç°æœ‰æ•°æ®è½¬æ¢ä¸ºDataFrameä»¥ä¾¿æ¯”è¾ƒ
        # å‡è®¾ç°æœ‰æ•°æ®çš„ç¬¬ä¸€åˆ—æ˜¯æ—¥æœŸï¼ˆé€šå¸¸æ˜¯äº¤æ˜“æ—¥æœŸï¼‰
        existing_dates = []
        for row in existing_data:
            if row:  # ç¡®ä¿è¡Œä¸ä¸ºç©º
                existing_dates.append(str(row[0]))  # ç¬¬ä¸€åˆ—æ˜¯æ—¥æœŸ
        
        print(f"ğŸ“… ç°æœ‰æ•°æ®ä¸­çš„æ—¥æœŸæ•°é‡: {len(existing_dates)}")
        if existing_dates:
            print(f"ç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ: {existing_dates[0]}")
            print(f"ç°æœ‰æ•°æ®çš„æœ€æ—©æ—¥æœŸ: {existing_dates[-1]}")
        
        # è·å–æ–°æ•°æ®ä¸­çš„æ—¥æœŸåˆ—ï¼ˆå‡è®¾æ˜¯ç¬¬ä¸€åˆ—ï¼‰
        if df.empty:
            print("âŒ æ–°æ•°æ®ä¸ºç©º")
            return pd.DataFrame()
        
        # è·å–æ—¥æœŸåˆ—ï¼ˆå°è¯•æ‰¾åˆ°æ—¥æœŸåˆ—åï¼Œå¦åˆ™ç”¨ç¬¬ä¸€åˆ—ï¼‰
        date_column = None
        for col in df.columns:
            if 'æ—¥æœŸ' in col or 'date' in col.lower():
                date_column = col
                break
        
        if not date_column:
            date_column = df.columns[0]
            print(f"âš ï¸ æœªæ‰¾åˆ°æ˜ç¡®çš„æ—¥æœŸåˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—: {date_column}")
        
        new_dates = df[date_column].astype(str).tolist()
        print(f"æ–°æ•°æ®ä¸­çš„æœ€æ–°æ—¥æœŸ: {new_dates[0] if new_dates else 'æ— '}")
        print(f"æ–°æ•°æ®ä¸­çš„æœ€æ—©æ—¥æœŸ: {new_dates[-1] if new_dates else 'æ— '}")
        
        # æ‰¾å‡ºæ–°å¢çš„æ—¥æœŸ
        new_date_indices = []
        for i, date in enumerate(new_dates):
            if str(date) not in existing_dates:
                new_date_indices.append(i)
        
        print(f"ğŸ” æ‰¾åˆ° {len(new_date_indices)} æ¡æ–°å¢æ•°æ®")
        
        if new_date_indices:
            # æå–æ–°å¢æ•°æ®
            new_data_df = df.iloc[new_date_indices].copy()
            print(f"æ–°å¢æ•°æ®æ—¥æœŸ: {new_data_df[date_column].head().tolist()}")
            return new_data_df
        else:
            print("âœ… æ²¡æœ‰å‘ç°æ–°å¢æ•°æ®ï¼Œæ‰€æœ‰æ•°æ®éƒ½å·²å­˜åœ¨")
            return pd.DataFrame()
            
    except Exception as e:
        print(f"âŒ è¯†åˆ«æ–°å¢æ•°æ®æ—¶å‡ºé”™: {e}")
        print("å°†å°è¯•å°†æ‰€æœ‰æ•°æ®ä½œä¸ºæ–°å¢æ•°æ®å¤„ç†")
        return df

def prepare_update_data(new_data_df, existing_headers):
    """
    å‡†å¤‡è¦æ›´æ–°åˆ°é£ä¹¦çš„æ•°æ®æ ¼å¼
    
    å‚æ•°:
    new_data_df: æ–°å¢æ•°æ®çš„DataFrame
    existing_headers: é£ä¹¦è¡¨æ ¼ä¸­ç°æœ‰çš„è¡¨å¤´
    
    è¿”å›:
    feishu_data: é£ä¹¦APIæ‰€éœ€çš„äºŒç»´åˆ—è¡¨æ ¼å¼
    """
    if new_data_df is None or new_data_df.empty:
        print("âš ï¸ æ²¡æœ‰æ–°å¢æ•°æ®éœ€è¦æ›´æ–°")
        return []
    
    try:
        # ç¡®ä¿æœ‰æ›´æ–°æ—¶é—´åˆ—
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        new_data_df = new_data_df.copy()
        
        # å¦‚æœè¿˜æ²¡æœ‰æ›´æ–°æ—¶é—´åˆ—ï¼Œåˆ™æ·»åŠ 
        if 'æ›´æ–°æ—¶é—´' not in new_data_df.columns:
            new_data_df['æ›´æ–°æ—¶é—´'] = current_time
        
        # å°†æ•°æ®è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        data_rows = []
        for _, row in new_data_df.iterrows():
            # å°†æ¯è¡Œæ•°æ®è½¬æ¢ä¸ºåˆ—è¡¨
            row_data = []
            for value in row:
                # å¤„ç†NaNå€¼ï¼Œé£ä¹¦ä¸æ¥å—NaN
                if pd.isna(value):
                    row_data.append("")
                else:
                    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                    row_data.append(str(value))
            data_rows.append(row_data)
        
        print(f"âœ… å‡†å¤‡å®Œæˆ {len(data_rows)} è¡Œæ–°å¢æ•°æ®")
        return data_rows
    except Exception as e:
        print(f"âŒ å‡†å¤‡æ•°æ®æ—¶å‡ºé”™: {e}")
        return []

def append_to_feishu(feishu_data, token):
    """
    å°†æ–°å¢æ•°æ®è¿½åŠ åˆ°é£ä¹¦è¡¨æ ¼
    
    å‚æ•°:
    feishu_data: è¦è¿½åŠ çš„æ•°æ®ï¼ˆäºŒç»´åˆ—è¡¨ï¼Œä¸åŒ…å«è¡¨å¤´ï¼‰
    token: é£ä¹¦è®¿é—®ä»¤ç‰Œ
    """
    if not feishu_data:
        print("âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦è¿½åŠ ")
        return True
    
    try:
        # é£ä¹¦è¡¨æ ¼è¿½åŠ æ•°æ®çš„API
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values_append"
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json; charset=utf-8"
        }
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        # æ³¨æ„ï¼šè¿™é‡ŒvaluesåªåŒ…å«æ•°æ®è¡Œï¼Œä¸åŒ…å«è¡¨å¤´
        request_data = {
            "valueRange": {
                "range": SHEET_ID,  # å·¥ä½œè¡¨ID
                "values": feishu_data
            }
        }
        
        # å‘é€è¯·æ±‚
        print(f"æ­£åœ¨è¿½åŠ  {len(feishu_data)} è¡Œæ–°æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼...")
        response = requests.post(url, headers=headers, json=request_data)
        result = response.json()
        
        # æ£€æŸ¥å“åº”
        if result.get("code") == 0:
            updates = result.get("data", {}).get("updates", {})
            print(f"âœ… æˆåŠŸè¿½åŠ æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼ï¼")
            print(f"æ›´æ–°èŒƒå›´ï¼š{updates.get('updatedRange', 'æœªçŸ¥')}")
            print(f"æ›´æ–°è¡Œæ•°ï¼š{updates.get('updatedRows', 'æœªçŸ¥')}")
            return True
        else:
            print(f"âŒ è¿½åŠ æ•°æ®å¤±è´¥: {result}")
            
            # å°è¯•å…¶ä»–æ–¹æ³•ï¼šå¦‚æœè¿½åŠ å¤±è´¥ï¼Œå°è¯•æ™®é€šæ›´æ–°
            print("å°è¯•ä½¿ç”¨æ›´æ–°æ¥å£...")
            return update_to_feishu(feishu_data, token)
    except Exception as e:
        print(f"âŒ è¿½åŠ æ•°æ®æ—¶å‡ºé”™: {e}")
        return False

def update_to_feishu(feishu_data, token):
    """
    å¤‡ç”¨æ›´æ–°æ–¹æ³•ï¼šä½¿ç”¨æ™®é€šæ›´æ–°æ¥å£
    """
    try:
        # é¦–å…ˆè·å–å½“å‰æ•°æ®è¡Œæ•°
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values/{SHEET_ID}"
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.get(url, headers=headers)
        result = response.json()
        
        if result.get("code") == 0:
            data = result.get("data", {})
            values = data.get("valueRange", {}).get("values", [])
            current_row_count = len(values) if values else 1  # è‡³å°‘1è¡Œï¼ˆè¡¨å¤´ï¼‰
            
            # è®¡ç®—èµ·å§‹è¡Œå·ï¼ˆä»1å¼€å§‹ï¼‰
            start_row = current_row_count + 1
            
            # æ›´æ–°URLï¼ˆæŒ‡å®šå…·ä½“èŒƒå›´ï¼‰
            update_url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values"
            
            # æ„å»ºæ›´æ–°èŒƒå›´ï¼Œä¾‹å¦‚ï¼š"9ee237!A10:C20"
            end_row = start_row + len(feishu_data) - 1
            col_count = len(feishu_data[0]) if feishu_data else 1
            end_col = chr(65 + col_count - 1) if col_count <= 26 else 'Z'  # A-Zåˆ—
            
            range_str = f"{SHEET_ID}!A{start_row}:{end_col}{end_row}"
            
            update_data = {
                "valueRanges": [{
                    "range": range_str,
                    "values": feishu_data
                }]
            }
            
            update_response = requests.put(update_url, headers=headers, json=update_data)
            update_result = update_response.json()
            
            if update_result.get("code") == 0:
                print(f"âœ… æˆåŠŸæ›´æ–°æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼ï¼")
                print(f"æ›´æ–°èŒƒå›´ï¼š{range_str}")
                return True
            else:
                print(f"âŒ æ›´æ–°æ•°æ®å¤±è´¥: {update_result}")
                return False
        else:
            print(f"âŒ æ— æ³•è·å–å½“å‰æ•°æ®è¡Œæ•°: {result}")
            return False
    except Exception as e:
        print(f"âŒ æ›´æ–°æ•°æ®æ—¶å‡ºé”™: {e}")
        return False

def incremental_update():
    """
    ä¸»å‡½æ•°ï¼šå®ç°å¢é‡æ›´æ–°ï¼Œåªæ·»åŠ æ–°æ•°æ®
    """
    print("=" * 60)
    print("æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ•°æ® - å¢é‡æ›´æ–°")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if not all([APP_ID, APP_SECRET, TABLE_TOKEN, SHEET_ID]):
            print("âŒ ç¯å¢ƒå˜é‡æœªè®¾ç½®å®Œæ•´")
            print("è¯·åœ¨GitHubä»“åº“çš„Settings -> Secrets and variables -> Actionsä¸­è®¾ç½®:")
            print("APP_ID, APP_SECRET, TABLE_TOKEN, SHEET_ID")
            return False
        
        # æ­¥éª¤1ï¼šè·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ
        print("\n1ï¸âƒ£ è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
        token = get_feishu_token()
        if not token:
            print("âŒ æ— æ³•è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
            return False
        
        # æ­¥éª¤2ï¼šä»é£ä¹¦è¡¨æ ¼è¯»å–ç°æœ‰æ•°æ®
        print("\n2ï¸âƒ£ è¯»å–é£ä¹¦è¡¨æ ¼ä¸­çš„ç°æœ‰æ•°æ®")
        existing_data, existing_headers = read_existing_feishu_data(token)
        
        # æ­¥éª¤3ï¼šè·å–æœ€æ–°çš„ç»“ç®—æ±‡ç‡æ•°æ®
        print("\n3ï¸âƒ£ è·å–æœ€æ–°çš„ç»“ç®—æ±‡ç‡æ•°æ®")
        df = get_settlement_exchange_rate()
        
        if df is None or df.empty:
            print("âŒ æ— æ³•è·å–ç»“ç®—æ±‡ç‡æ•°æ®")
            return False
        
        # æ­¥éª¤4ï¼šå‡†å¤‡æ–°æ•°æ®
        print("\n4ï¸âƒ£ å‡†å¤‡æ–°æ•°æ®")
        prepared_df = prepare_new_data(df)
        
        if prepared_df.empty:
            print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥")
            return False
        
        # æ­¥éª¤5ï¼šè¯†åˆ«æ–°å¢æ•°æ®
        print("\n5ï¸âƒ£ è¯†åˆ«æ–°å¢æ•°æ®")
        new_data_df = identify_new_data(prepared_df, existing_data, existing_headers)
        
        if new_data_df.empty:
            print("âœ… æ²¡æœ‰å‘ç°æ–°å¢æ•°æ®ï¼Œæ— éœ€æ›´æ–°")
            print("=" * 60)
            return True
        
        # æ­¥éª¤6ï¼šå‡†å¤‡æ•°æ®æ ¼å¼
        print("\n6ï¸âƒ£ å‡†å¤‡æ•°æ®æ ¼å¼")
        feishu_data = prepare_update_data(new_data_df, existing_headers)
        
        if not feishu_data:
            print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥")
            return False
        
        # æ­¥éª¤7ï¼šè¿½åŠ æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼
        print("\n7ï¸âƒ£ è¿½åŠ æ–°å¢æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼")
        success = append_to_feishu(feishu_data, token)
        
        if success:
            print("\n" + "=" * 60)
            print(f"ğŸ‰ å¢é‡æ›´æ–°æˆåŠŸï¼æ–°å¢ {len(feishu_data)} æ¡æ•°æ®")
            print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("=" * 60)
            return True
        else:
            print("\n" + "=" * 60)
            print("âŒ å¢é‡æ›´æ–°å¤±è´¥")
            print("=" * 60)
            return False
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def full_sync():
    """
    å®Œæ•´åŒæ­¥ï¼šæ¸…ç©ºæ—§æ•°æ®ï¼Œé‡æ–°å¯¼å…¥æ‰€æœ‰æ•°æ®ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
    """
    print("=" * 60)
    print("æ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ•°æ® - å®Œæ•´åŒæ­¥")
    print("=" * 60)
    
    # è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ
    token = get_feishu_token()
    if not token:
        return False
    
    # è·å–æ•°æ®
    df = get_settlement_exchange_rate()
    if df is None or df.empty:
        return False
    
    # å‡†å¤‡æ•°æ®ï¼ˆåŒ…å«è¡¨å¤´ï¼‰
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    df = df.copy()
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰'æ›´æ–°æ—¶é—´'åˆ—
    if 'æ›´æ–°æ—¶é—´' not in df.columns:
        df['æ›´æ–°æ—¶é—´'] = current_time
    
    # è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆåŒ…å«è¡¨å¤´ï¼‰
    headers = df.columns.tolist()
    data_rows = []
    for _, row in df.iterrows():
        row_data = [str(row[col]) if not pd.isna(row[col]) else "" for col in headers]
        data_rows.append(row_data)
    
    feishu_data = [headers] + data_rows
    
    # æ¸…ç©ºè¡¨æ ¼
    print("\næ¸…ç©ºè¡¨æ ¼...")
    clear_url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values_clear"
    headers_auth = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    clear_data = {
        "range": SHEET_ID
    }
    
    clear_response = requests.post(clear_url, headers=headers_auth, json=clear_data)
    
    # å†™å…¥æ‰€æœ‰æ•°æ®
    print("å†™å…¥æ‰€æœ‰æ•°æ®...")
    url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{TABLE_TOKEN}/values"
    update_data = {
        "valueRanges": [{
            "range": SHEET_ID,
            "values": feishu_data
        }]
    }
    
    response = requests.put(url, headers=headers_auth, json=update_data)
    result = response.json()
    
    if result.get("code") == 0:
        print(f"âœ… å®Œæ•´åŒæ­¥æˆåŠŸï¼å…± {len(data_rows)} æ¡æ•°æ®")
        return True
    else:
        print(f"âŒ å®Œæ•´åŒæ­¥å¤±è´¥: {result}")
        return False

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    print("å¼€å§‹æ‰§è¡Œæ²ªæ¸¯é€šç»“ç®—æ±‡ç‡æ›´æ–°ç¨‹åº...")
    
    # åœ¨GitHub Actionsä¸­æ€»æ˜¯æ‰§è¡Œå¢é‡æ›´æ–°
    result = incremental_update()
    
    if result:
        print("ç¨‹åºæ‰§è¡ŒæˆåŠŸï¼")
        sys.exit(0)  # æˆåŠŸé€€å‡º
    else:
        print("ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼")
        sys.exit(1)  # å¤±è´¥é€€å‡º
